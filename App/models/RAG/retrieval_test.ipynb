{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## retrieval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import (\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever,\n",
    "    ContextualCompressionRetriever,\n",
    ")\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.evaluation import QAEvalChain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import time\n",
    "\n",
    "class RetrievalExperiment:\n",
    "    def __init__(self, db: Chroma, llm, embedding_model, test_questions: List[Dict]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            db: ChromaDB 인스턴스\n",
    "            llm: LLM 모델\n",
    "            embedding_model: 임베딩 모델\n",
    "            test_questions: [{\"question\": \"질문\", \"answer\": \"실제 답변\"}, ...] 형식의 테스트 데이터\n",
    "        \"\"\"\n",
    "        self.db = db\n",
    "        self.llm = llm\n",
    "        self.embedding_model = embedding_model\n",
    "        self.test_questions = test_questions\n",
    "        self.results = []\n",
    "\n",
    "    def setup_retrievers(self):\n",
    "        \"\"\"다양한 retriever 설정\"\"\"\n",
    "        retrievers = {\n",
    "            \"Basic\": self.db.as_retriever(\n",
    "                search_type=\"similarity\",\n",
    "                search_kwargs={\"k\": 3}\n",
    "            ),\n",
    "            \"MMR\": self.db.as_retriever(\n",
    "                search_type=\"mmr\",\n",
    "                search_kwargs={\"k\": 3, \"fetch_k\": 5}\n",
    "            ),\n",
    "            \"BM25\": BM25Retriever.from_documents(\n",
    "                self.db.get(),\n",
    "                k=3\n",
    "            ),\n",
    "            \"Ensemble\": self._create_ensemble_retriever(),\n",
    "            \"Contextual\": self._create_contextual_retriever(),\n",
    "        }\n",
    "        return retrievers\n",
    "\n",
    "    def _create_ensemble_retriever(self):\n",
    "        \"\"\"BM25와 벡터 검색을 결합한 앙상블 retriever 생성\"\"\"\n",
    "        bm25_retriever = BM25Retriever.from_documents(\n",
    "            self.db.get(),\n",
    "            k=3\n",
    "        )\n",
    "        vector_retriever = self.db.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "        \n",
    "        return EnsembleRetriever(\n",
    "            retrievers=[bm25_retriever, vector_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "    def _create_contextual_retriever(self):\n",
    "        \"\"\"컨텍스트 기반 압축 retriever 생성\"\"\"\n",
    "        base_retriever = self.db.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "        \n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        \n",
    "        return ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=base_retriever\n",
    "        )\n",
    "\n",
    "    def evaluate_retriever(self, retriever, retriever_name: str):\n",
    "        \"\"\"각 retriever의 성능 평가\"\"\"\n",
    "        start_time = time.time()\n",
    "        metrics = {\n",
    "            \"retriever_name\": retriever_name,\n",
    "            \"relevant_docs\": 0,\n",
    "            \"response_time\": 0,\n",
    "            \"precision\": 0,\n",
    "            \"recall\": 0\n",
    "        }\n",
    "        \n",
    "        total_questions = len(self.test_questions)\n",
    "        \n",
    "        for test_case in self.test_questions:\n",
    "            # 문서 검색\n",
    "            docs = retriever.get_relevant_documents(test_case[\"question\"])\n",
    "            \n",
    "            # 관련 문서 수 계산\n",
    "            relevant_docs = sum(1 for doc in docs if any(\n",
    "                keyword in doc.page_content.lower() \n",
    "                for keyword in test_case[\"answer\"].lower().split()\n",
    "            ))\n",
    "            \n",
    "            metrics[\"relevant_docs\"] += relevant_docs\n",
    "            metrics[\"precision\"] += relevant_docs / len(docs)\n",
    "            metrics[\"recall\"] += relevant_docs / len(test_case[\"answer\"].split())\n",
    "\n",
    "        # 평균 계산\n",
    "        metrics[\"relevant_docs\"] /= total_questions\n",
    "        metrics[\"precision\"] /= total_questions\n",
    "        metrics[\"recall\"] /= total_questions\n",
    "        metrics[\"response_time\"] = time.time() - start_time\n",
    "        \n",
    "        self.results.append(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def run_experiments(self):\n",
    "        \"\"\"모든 retriever에 대한 실험 실행\"\"\"\n",
    "        retrievers = self.setup_retrievers()\n",
    "        \n",
    "        for name, retriever in retrievers.items():\n",
    "            print(f\"\\nTesting {name} retriever...\")\n",
    "            metrics = self.evaluate_retriever(retriever, name)\n",
    "            print(f\"Results for {name}:\")\n",
    "            print(f\"Average relevant documents: {metrics['relevant_docs']:.2f}\")\n",
    "            print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "            print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "            print(f\"Response time: {metrics['response_time']:.2f} seconds\")\n",
    "\n",
    "    def get_best_retriever(self) -> str:\n",
    "        \"\"\"최적의 retriever 선정\"\"\"\n",
    "        df = pd.DataFrame(self.results)\n",
    "        \n",
    "        # 각 메트릭에 가중치 부여\n",
    "        weights = {\n",
    "            'precision': 0.4,\n",
    "            'recall': 0.3,\n",
    "            'relevant_docs': 0.2,\n",
    "            'response_time': 0.1\n",
    "        }\n",
    "        \n",
    "        # response_time은 역수로 변환 (작을수록 좋음)\n",
    "        df['response_time_inv'] = 1 / df['response_time']\n",
    "        \n",
    "        # 정규화\n",
    "        for col in ['precision', 'recall', 'relevant_docs', 'response_time_inv']:\n",
    "            df[f'{col}_norm'] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "        \n",
    "        # 총점 계산\n",
    "        df['score'] = (\n",
    "            weights['precision'] * df['precision_norm'] +\n",
    "            weights['recall'] * df['recall_norm'] +\n",
    "            weights['relevant_docs'] * df['relevant_docs_norm'] +\n",
    "            weights['response_time'] * df['response_time_inv_norm']\n",
    "        )\n",
    "        \n",
    "        best_retriever = df.loc[df['score'].idxmax(), 'retriever_name']\n",
    "        return best_retriever\n",
    "\n",
    "    def save_results(self, filename: str = \"retrieval_experiment_results.json\"):\n",
    "        \"\"\"실험 결과 저장\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 테스트 데이터 예시\n",
    "    test_questions = [\n",
    "        {\n",
    "            \"question\": \"시각장애인 보조견 동반 출입 거부 시 처벌 규정이 있나요?\",\n",
    "            \"answer\": \"장애인복지법에 따라 과태료 처분을 받을 수 있습니다.\"\n",
    "        },\n",
    "        # 더 많은 테스트 케이스 추가\n",
    "    ]\n",
    "    \n",
    "    # 실험 실행\n",
    "    experiment = RetrievalExperiment(db, llm, embedding_model, test_questions)\n",
    "    experiment.run_experiments()\n",
    "    \n",
    "    # 최적의 retriever 확인\n",
    "    best_retriever = experiment.get_best_retriever()\n",
    "    print(f\"\\nBest performing retriever: {best_retriever}\")\n",
    "    \n",
    "    # 결과 저장\n",
    "    experiment.save_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "service-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
