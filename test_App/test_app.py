import yaml
import os
import streamlit as st
from audio_recorder_streamlit import audio_recorder
from models.STT.STT_models import STTModel
# from models.TTS.TTS_models import TTSModel  # TTS ëª¨ë¸ import ì¶”ê°€

class Config:
    def __init__(self, config_path):
        self.config = self.load_config(config_path)

    def load_config(self, path: str):
        with open(path, 'r') as f:
            config = yaml.safe_load(f)
        return config
    
    def get(self, key):
        return self.config[key]

class VoiceBot:
    def __init__(self):
        self.config = Config('test_App/config.yaml')
        
        # session_state ì´ˆê¸°í™”
        if 'is_recording' not in st.session_state:
            st.session_state.is_recording = False
        if 'stt_model' not in st.session_state:
            st.session_state.stt_model = self.load_stt_model(self.config)
        if 'tts_model' not in st.session_state:  # TTS ëª¨ë¸ ì„¸ì…˜ ìƒíƒœ ì¶”ê°€
            st.session_state.tts_model = self.load_tts_model(self.config)
        if 'conversation_history' not in st.session_state:  # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            st.session_state.conversation_history = []

        st.set_page_config(
            page_title="ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ë³´ì´ìŠ¤ ë´‡",
            page_icon="ğŸ¤",
            layout="centered"
        )

        # CSS ìŠ¤íƒ€ì¼ (ì´ì „ê³¼ ë™ì¼)
        st.markdown("""
            <style>
            .block-container {
                padding: 0;
            }
            
            .element-container {
                position: fixed;
                top: 50%;
                left: 72%;
                transform: translate(-50%, -50%);
                margin: 0 !important;
            }
            
            .audio-recorder {
                width: 200px !important;
                height: 200px !important;
                border-radius: 50% !important;
                background-color: #FF4B4B !important;
                border: none !important;
                display: flex !important;
                justify-content: center !important;
                align-items: center !important;
                padding: 0 !important;
                cursor: pointer !important;
                margin: 0 auto !important;
            }

            .audio-recorder:hover {
                background-color: #FF0000 !important;
            }

            .audio-recorder:active {
                background-color: #CC0000 !important;
            }

            .audio-recorder svg {
                width: 100px !important;
                height: 100px !important;
                fill: white !important;
            }

            .stAudio {
                position: fixed;
                left: 50%;
                transform: translateX(-50%);
                bottom: 20px;
                width: auto;
            }
            
            .stAudio > div {
                display: flex;
                justify-content: center;
            }
            </style>
        """, unsafe_allow_html=True)
    
    def load_stt_model(self, config):
        model = STTModel(config)
        return model
    
    def load_tts_model(self, config):  # TTS ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ ì¶”ê°€
        # model = TTSModel(config)
        # return model
        pass
        
    def speech_to_text(self, audio_bytes):
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        model = st.session_state.stt_model
        return model.transcribe(audio_bytes)
    
    def text_to_speech(self, text):  # TTS í•¨ìˆ˜ ì¶”ê°€
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        model = st.session_state.tts_model
        return model.synthesize(text)
    
    def process_conversation(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ ìƒì„±"""
        # ì—¬ê¸°ì— ì±—ë´‡ ë¡œì§ êµ¬í˜„
        # ì˜ˆì‹œë¡œ ê°„ë‹¨í•œ ì—ì½” ì‘ë‹µ
        response = f"ì…ë ¥í•˜ì‹  ë‚´ìš©ì€: {user_input}"
        return response
        
    def recording(self):
        # ì˜¤ë””ì˜¤ ë…¹ìŒ ì²˜ë¦¬
        audio_bytes = audio_recorder(
            text="",
            recording_color="#e87474",
            neutral_color="#6aa36f",
            icon_size="6x"
        )
        
        if audio_bytes:
            # ì‚¬ìš©ì ìŒì„± ì¬ìƒ
            st.audio(audio_bytes, format="audio/wav")

            try:
                # STTë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                user_text = self.speech_to_text(audio_bytes)
                print("ìŒì„± ì¸ì‹ ê²°ê³¼:", user_text)
                
                # ëŒ€í™” ì²˜ë¦¬
                response_text = self.process_conversation(user_text)
                
                # TTSë¡œ ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
                response_audio = self.text_to_speech(response_text)
                
                # ì‘ë‹µ ìŒì„± ì¬ìƒ
                st.audio(response_audio, format="audio/wav")
                
                # ëŒ€í™” ê¸°ë¡ ì €ì¥
                st.session_state.conversation_history.append({
                    "user": user_text,
                    "bot": response_text
                })
                
            except Exception as e:
                print(f"Error processing audio: {str(e)}")
                
    def run(self):
        self.recording()

if __name__ == "__main__":
    print(os.getcwd())
    VoiceBot().run()